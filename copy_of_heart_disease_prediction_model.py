# -*- coding: utf-8 -*-
"""Copy of Heart Disease Prediction Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tH35w73hxB3B8uTusEbxFoO8gvTb4VKA

**Heart Disease Prediction Project**

***Introduction***

This project aims to develop a machine learning model to predict the likelihood of heart disease in patients based on their medical attributes. By leveraging a neural network, the model analyzes various health metrics to provide accurate predictions, assisting in early diagnosis and prevention. The project utilizes the UCI Heart Disease dataset, which contains 14 features such as age, cholesterol levels, chest pain type, and other clinical measurements.
Data Source: https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data


***Amar Ahmed***

**Data scientist** | **Machine Learning Developer** | **Computer Vision Researcher**
"""

!pip install ydata_profiling

# import library
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from ydata_profiling import ProfileReport
from keras.utils import plot_model

# Reading Data
Data = pd.read_csv('heart_disease_uci.csv')
Data.head()

"""**EDA**"""

# Data Overview
display("Data size:", Data.shape)
print('--------------------------------------------')
display("\n columns:", Data.columns.tolist())
print('--------------------------------------------')
display("\n Data type:", Data.dtypes)
print('--------------------------------------------')

Data.tail()

Data.info()

Data.isnull().sum()

plt.figure(figsize=(10, 6))
sns.heatmap(Data.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Values Heatmap')
plt.show()

Data.duplicated().sum()

Data.describe()

Data.describe(include='object')

Data['target'] = Data['num'].apply(lambda x: 1 if x > 0 else 0)
Data.drop('num', axis=1, inplace=True)
Data['target'].value_counts()

# Visualize target distribution
plt.figure(figsize=(8, 5))
sns.countplot(x='target', data=Data)
plt.title('Distribution of Target (0: Not Diseased, 1: Diseased)')
plt.show()

Data['target']

# full Report
ProfileReport(Data)

# numeric columns
numeric_cols = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']

plt.figure(figsize=(15, 10))
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(2, 3, i)
    sns.histplot(Data[col], kde=True)
    plt.title(f'Distribution of {col}')
plt.tight_layout()
plt.show()

# categorical columns
categorical_cols = ['sex', 'dataset', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']

plt.figure(figsize=(15, 12))
for i, col in enumerate(categorical_cols, 1):
    plt.subplot(3, 3, i)
    sns.countplot(x=col, data=Data)
    plt.title(f'Distribution of {col}')
    plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Relationships with the target
df_temp = Data.copy()
for col in numeric_cols:
    plt.figure(figsize=(8, 5))
    sns.boxplot(x='target', y=col, data=df_temp)
    plt.title(f'{col} vs Target')
    plt.show()
for col in categorical_cols:
    plt.figure(figsize=(8, 5))
    sns.countplot(x=col, hue='target', data=df_temp)
    plt.title(f'{col} vs Target')
    plt.xticks(rotation=45)
    plt.show()

plt.figure(figsize=(12, 6))
sns.histplot(Data['target'], kde=True, color='purple', bins=20)
plt.title('Distribution of target (with KDE)')
plt.xlabel('target')
plt.ylabel('Frequency')
plt.show()

# correlation
numeric_data = Data.select_dtypes(include=np.number)

plt.figure(figsize=(15, 10))
sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

"""Data clenning & Data preprocessing"""

# preprocessing Data
def preprocessing_functions():
    global Data
    numeric_cols = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']
    categorical_cols = ['fbs', 'exang', 'slope', 'thal', 'cp', 'restecg']
    Data['trestbps'] = Data['trestbps'].replace(0, np.nan)
    Data['chol'] = Data['chol'].replace(0, np.nan)
    for col in numeric_cols:
        Data[col] = Data[col].fillna(Data[col].median())
    for col in categorical_cols:
        mode_value = Data[col].mode()
        if not mode_value.empty:
            Data[col] = Data[col].fillna(mode_value[0])
    # Convert binary columns
    Data['sex'] = Data['sex'].map({'Male': 1, 'Female': 0, 'male': 1, 'female': 0}).fillna(0).astype(int)
    Data['fbs'] = Data['fbs'].map({True: 1, False: 0, 'True': 1, 'False': 0, np.nan: 0}).astype(int)
    Data['exang'] = Data['exang'].map({True: 1, False: 0, 'True': 1, 'False': 0, np.nan: 0}).astype(int)

    # One-Hot Encoding
    one_hot_encoder = OneHotEncoder(sparse_output=False, drop='first')
    encoded_data = one_hot_encoder.fit_transform(Data[['cp', 'restecg', 'slope', 'thal']])
    encoded_columns = one_hot_encoder.get_feature_names_out(['cp', 'restecg', 'slope', 'thal'])
    encoded_df = pd.DataFrame(encoded_data, columns=encoded_columns, index=Data.index)
    Data.drop(['cp', 'restecg', 'slope', 'thal'], axis=1, inplace=True)
    Data = pd.concat([Data, encoded_df], axis=1)
preprocessing_functions()

Data

sns.pairplot(Data, hue='target')
plt.show()

"""**Spliting Dataset**"""

from imblearn.over_sampling import SMOTE
# spliting
X = Data.drop(['target', 'id', 'dataset'], axis=1)
y = Data['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# SMOTE
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

# scaler
scaler = StandardScaler()
X_train_scaler = scaler.fit_transform(X_train_res)
X_test_scaler = scaler.transform(X_test)

"""**Train Model**"""

from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping
def MODEL_TRAIN():
    model = Sequential([
        Dense(128, activation='relu', input_shape=(X_train_scaler.shape[1],), kernel_regularizer=l2(0.01)),
        Dropout(0.3),
        Dense(64, activation='relu', kernel_regularizer=l2(0.01)),
        Dropout(0.3),
        Dense(32, activation='relu', kernel_regularizer=l2(0.01)),
        Dropout(0.3),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    history = model.fit(X_train_scaler,
                        y_train_res,
                        epochs=100,
                        batch_size=32,
                        validation_split=0.2,
                        callbacks=[early_stopping])
    return model
MODEL = MODEL_TRAIN()

# Evaluate Model
test_loss, test_accuracy = MODEL.evaluate(X_test_scaler, y_test)
print(f"Test Accuracy: {test_accuracy:.4f}")

# Save Model
MODEL.save('heart_disease_model.h5')
import joblib
joblib.dump(scaler, 'scaler.pkl')

"""**Metrics Test**"""

y_pred = MODEL.predict(X_test_scaler)
y_pred[:10]

y_test[:10]

from sklearn.metrics import classification_report
y_pred = MODEL.predict(X_test_scaler)
report = classification_report(y_test, y_pred.round())
print(report)

from sklearn.metrics import confusion_matrix

matrix = confusion_matrix(y_test, y_pred.round())
plt.figure(figsize=(8, 6))
sns.heatmap(matrix, annot=True , fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')

"""**Building a simple application for gradio**

"""

!pip install gradio

import gradio as gr
from tensorflow.keras.models import load_model
import numpy as np
import joblib

# Load Model
scaler = joblib.load('scaler.pkl')
model = load_model('heart_disease_model.h5')

# Prediction function
def predict_heart_disease(*features):
    input_data = np.array([features])
    input_scaled = scaler.transform(input_data)
    prediction = model.predict(input_scaled)[0][0]
    return f"Possibility of infection : {prediction:.2f} ({'injured' if prediction > 0.5 else 'Healthy'})"

# feature names
feature_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs',
                 'restecg', 'thalch', 'exang', 'oldpeak', 'slope', 'thal']

# Gradio interface
inputs = [gr.Number(label=name) for name in feature_names]

interface = gr.Interface(
    fn=predict_heart_disease,
    inputs=inputs,
    outputs="text",
    title="Heart Disease Prediction Model",
    description="Enter the required values ​​to predict the heart condition (Affected / Healthy)."
)

interface.launch()

"""
***Thank you for checking out this notebook! ❤️❤️***"""